{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "import concurrent\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que este notebook ira realizar:\n",
    "-------------------------------\n",
    "\n",
    "1. Acessar o site da olx utilizando a biblioteca **BeautifulSoup**, ecnontrar a lista de preços e salvar cada item em uma lista de \"Tags\"\n",
    "2. Encontrar os valores (municipio, estado , categoria, titulo, preco, link) de cada anuncio na lista\n",
    "3. Salvar em um DataFrame do Pandas\n",
    "4. Acessar cada um dos links de cada anuncio no DataFrame, no campo **href** e retira dele o CEP de cada anuncio criando um dicionario neste formato {\"href\":\"cep\"} **(Esta parte do codigo precisa ser aprimorada atualmente demora em torno de 5 à 7min para executar)**\n",
    "5. Adicionar o dicionario de CEP ao dataframe de anuncios utilizando a função _.map_ do Pandas \n",
    "6. Salvar o DataFrame resultante em uma planilha Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['local', 'categoria', 'titulo', 'preco', 'href', 'data']\n",
    "cep_dict = {}\n",
    "url_leste = \"http://sp.olx.com.br/sao-paulo-e-regiao/zona-leste/imoveis?o=\"\n",
    "url_oeste = 'http://sp.olx.com.br/sao-paulo-e-regiao/zona-oeste/imoveis?o='\n",
    "url_centro = 'http://sp.olx.com.br/sao-paulo-e-regiao/centro/imoveis?o='\n",
    "url_norte = 'http://sp.olx.com.br/sao-paulo-e-regiao/zona-norte/imoveis?o='\n",
    "url_sul = 'http://sp.olx.com.br/sao-paulo-e-regiao/zona-sul/imoveis?o='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retornaSoupOLX(url, num):\n",
    "    li_list = []\n",
    "    headers = requests.utils.default_headers()\n",
    "    headers.update({\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0',\n",
    "    })\n",
    "    for iter in range(num):\n",
    "        sleep(1)\n",
    "        r = requests.get(str(url)+str(iter), headers=headers)\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        for ultag in soup.find_all('ul', {'class': 'list', 'id':'main-ad-list' }):\n",
    "            for litag in ultag.find_all(lambda tag: tag.name == 'li' and tag.get('class') == ['item']):\n",
    "                li_list.append(litag)\n",
    "    return li_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiraEspecialString(string):\n",
    "    return string.text.replace('\\n','').replace('\\t','').replace('R$ ', '').replace('.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiraEspecialFloat(string):\n",
    "    return string.text.replace('\\n','').replace('\\t','').replace('R$ ', '').replace('.', '').replace(',', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def criaListaValores(li_list):\n",
    "    valores = []\n",
    "    for elements in li_list:\n",
    "        x = BeautifulSoup(str(elements), 'html.parser')\n",
    "        #encontra a parte onde estão as informaçoes no html\n",
    "        info = x.find('div', {'class':'col-2'})\n",
    "        #encontra a string onde estão o municipio e estado separados por virgula\n",
    "        cidade_estado = tiraEspecialString(info.find('div', {'class':'OLXad-list-line-2'}).find('p', {'class':'text detail-region'}))\n",
    "        #encontra a categoria do anuncio\n",
    "        categoria = tiraEspecialString(info.find('div', {'class':'OLXad-list-line-2'}).find('p', {'class':'text detail-category'}))\n",
    "        #encontra o titulo do anuncio\n",
    "        titulo = tiraEspecialString(info.find('div', {'class':'OLXad-list-line-1 mb5px'}).find('h3', {'class':'OLXad-list-title mb5px'}))\n",
    "        #encontra o html do preço\n",
    "        preco = x.find('div', {'class':'col-3'})\n",
    "        #encontra a data\n",
    "        data = x.find('div', {'class':'col-4'}).find('p', {'class':'text mb5px'}).text\n",
    "        \n",
    "        #trata o html do preço verificando se existe ou não\n",
    "        if preco.find('p', {'class':'OLXad-list-price'}):\n",
    "            preco = tiraEspecialFloat(x.find('div', {'class':'col-3'}).find('p', {'class':'OLXad-list-price'}))\n",
    "        else:\n",
    "            preco = 0.0\n",
    "        #retorna a tag href \"link do anuncio\"\n",
    "        href=x.find('a', {'class':'OLXad-list-link'})\n",
    "        \n",
    "        #retorna o conteudo do atributo href na tag href\n",
    "        href = href['href']\n",
    "        \n",
    "        valores.append([cidade_estado, categoria, titulo, preco, href, data])\n",
    "    return valores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCEP(url):\n",
    "    headers = requests.utils.default_headers()\n",
    "    headers.update({\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0',\n",
    "    })\n",
    "    regx = re.compile('\\d{5}-\\d{3}')\n",
    "    r = requests.get(url, headers = headers)\n",
    "    sleep(1)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    cep = soup.find(lambda tag: tag.name == 'strong' and tag.get('class') == ['description'] and regx.match(tag.text.strip(' \\t\\n\\r')) is not None)\n",
    "    if cep:\n",
    "        cep_dict.update({url:cep.text.strip(' \\t\\n\\r')})\n",
    "    else:\n",
    "        cep_dict.update({url:''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#cria as Soups de cada região\n",
    "soup_leste = retornaSoupOLX(url_leste, 1)\n",
    "soup_sul = retornaSoupOLX(url_sul,1)\n",
    "soup_norte = retornaSoupOLX(url_norte, 1)\n",
    "soup_oeste = retornaSoupOLX(url_oeste, 1)\n",
    "soup_centro = retornaSoupOLX(url_centro, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#cria lista com os valores separados de cada região\n",
    "valores_leste = criaListaValores(soup_leste)\n",
    "valores_sul = criaListaValores(soup_sul)\n",
    "valores_norte = criaListaValores(soup_norte)\n",
    "valores_oeste = criaListaValores(soup_oeste)\n",
    "valores_centro = criaListaValores(soup_centro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.23 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#cria o dataframe de cada uma das regiões\n",
    "df_norte = pd.DataFrame(valores_norte, columns=labels)\n",
    "df_sul = pd.DataFrame(valores_sul, columns=labels)\n",
    "df_leste = pd.DataFrame(valores_leste, columns=labels)\n",
    "df_oeste = pd.DataFrame(valores_oeste, columns=labels)\n",
    "df_centro = pd.DataFrame(valores_centro, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria uma coluna com a Zona de cada dataframe\n",
    "df_norte['zona'] = 'Norte'\n",
    "df_sul['zona'] = 'Sul'\n",
    "df_leste['zona'] = 'Leste'\n",
    "df_oeste['zona'] = 'Oeste'\n",
    "df_centro['zona'] = 'Centro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar uma lista de DataFrames e juntalos em apenas um\n",
    "df = pd.DataFrame()\n",
    "lista_df_zona = [\n",
    "    df_norte,\n",
    "    df_sul,\n",
    "    df_leste,\n",
    "    df_oeste,\n",
    "    df_centro\n",
    "]\n",
    "df = df.append(lista_df_zona, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retira as categorias que estão mal formatadas e cria uma coluna á parte para os anuncios profissionais\n",
    "df['categoria'] = df['categoria'].str.replace('- Anúncio Profissional', 'Profissional')\n",
    "df['categoria'] = df['categoria'].str.replace('Profissional', '- Profissional')\n",
    "df['categoria'], df['profissional'] = df['categoria'].str.split('-', 1).str\n",
    "df['profissional']=df.profissional.replace(' Profissional', True)\n",
    "df['profissional']=df.profissional.fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#selecionar casas com preços diferente de 0\n",
    "df_casa = df[df['categoria'] == 'Casas']\n",
    "df_casa['preco'] = df_casa['preco'].astype(float)\n",
    "df_casa = df_casa[df_casa['preco']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria uma lista com  os links de cada anuncio\n",
    "list_href = list(df_casa['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Usa Pools para realizar a busca de cep e adicionar ao dicionario 'dict_cep'\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=30) as e:\n",
    "     e.map(findCEP, list_href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cira um campo CEP no DataFrame juntando o dicionario criado anteriormente\n",
    "df_casa['cep'] = df_casa['href'].map(cep_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui dropa o antigo local e separa o 'São Paulo, Bairro' em duas colunas\n",
    "df_casa = pd.concat([df_casa , df_casa['local'].str.split(',', n=1, expand=True)], axis =1)\n",
    "df_casa.drop(['local', 0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui dropa o antigo local e separa o 'São Paulo, Bairro' em duas colunas\n",
    "df = pd.concat([df , df['local'].str.split(',', n=1, expand=True)], axis =1)\n",
    "df.drop(['local', 0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arruma as colunas criadas anteriormente\n",
    "df.columns = ['categoria', 'titulo', 'preco', 'href', 'data', 'zona','profissional', 'bairro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arruma as colunas criadas anteriormente\n",
    "df_casa.columns = ['categoria', 'titulo', 'preco', 'href', 'data', 'zona','profissional', 'cep', 'bairro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arruma a coluna bairro pois há um espaço como primeiro caractere em todos os registros\n",
    "df_casa['bairro'] = df_casa['bairro'].str.replace(' ', '', n=1)\n",
    "df['bairro'] = df['bairro'].str.replace(' ', '', n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoria</th>\n",
       "      <th>titulo</th>\n",
       "      <th>preco</th>\n",
       "      <th>href</th>\n",
       "      <th>data</th>\n",
       "      <th>zona</th>\n",
       "      <th>profissional</th>\n",
       "      <th>cep</th>\n",
       "      <th>bairro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Casas</td>\n",
       "      <td>Vendo casa em pirituba</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>http://sp.olx.com.br/sao-paulo-e-regiao/imovei...</td>\n",
       "      <td>&lt;p class=\"text mb5px\"&gt;Hoje&lt;/p&gt;</td>\n",
       "      <td>Norte</td>\n",
       "      <td>False</td>\n",
       "      <td>05172-090</td>\n",
       "      <td>Vila Pirituba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Casas</td>\n",
       "      <td>Aluga-se casa na Brasilândia R$750,00</td>\n",
       "      <td>750.0</td>\n",
       "      <td>http://sp.olx.com.br/sao-paulo-e-regiao/imovei...</td>\n",
       "      <td>&lt;p class=\"text mb5px\"&gt;Hoje&lt;/p&gt;</td>\n",
       "      <td>Norte</td>\n",
       "      <td>False</td>\n",
       "      <td>02844-090</td>\n",
       "      <td>Brasilândia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Casas</td>\n",
       "      <td>Casa</td>\n",
       "      <td>885000.0</td>\n",
       "      <td>http://sp.olx.com.br/sao-paulo-e-regiao/imovei...</td>\n",
       "      <td>&lt;p class=\"text mb5px\"&gt;Hoje&lt;/p&gt;</td>\n",
       "      <td>Norte</td>\n",
       "      <td>True</td>\n",
       "      <td>02311-010</td>\n",
       "      <td>Vila Mazzei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Casas</td>\n",
       "      <td>Cód 178 Casa 2 Dorm Tucuruvi 1200,00</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>http://sp.olx.com.br/sao-paulo-e-regiao/imovei...</td>\n",
       "      <td>&lt;p class=\"text mb5px\"&gt;Hoje&lt;/p&gt;</td>\n",
       "      <td>Norte</td>\n",
       "      <td>False</td>\n",
       "      <td>02248-030</td>\n",
       "      <td>Parada Inglesa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Casas</td>\n",
       "      <td>Quarto cozinha wc e lavan no jd hebrom - Jaçan...</td>\n",
       "      <td>650.0</td>\n",
       "      <td>http://sp.olx.com.br/sao-paulo-e-regiao/imovei...</td>\n",
       "      <td>&lt;p class=\"text mb5px\"&gt;Hoje&lt;/p&gt;</td>\n",
       "      <td>Norte</td>\n",
       "      <td>False</td>\n",
       "      <td>02329-060</td>\n",
       "      <td>Jardim Hebrom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  categoria                                             titulo     preco  \\\n",
       "0     Casas                             Vendo casa em pirituba  300000.0   \n",
       "1     Casas              Aluga-se casa na Brasilândia R$750,00     750.0   \n",
       "2     Casas                                               Casa  885000.0   \n",
       "3     Casas               Cód 178 Casa 2 Dorm Tucuruvi 1200,00    1200.0   \n",
       "4     Casas  Quarto cozinha wc e lavan no jd hebrom - Jaçan...     650.0   \n",
       "\n",
       "                                                href  \\\n",
       "0  http://sp.olx.com.br/sao-paulo-e-regiao/imovei...   \n",
       "1  http://sp.olx.com.br/sao-paulo-e-regiao/imovei...   \n",
       "2  http://sp.olx.com.br/sao-paulo-e-regiao/imovei...   \n",
       "3  http://sp.olx.com.br/sao-paulo-e-regiao/imovei...   \n",
       "4  http://sp.olx.com.br/sao-paulo-e-regiao/imovei...   \n",
       "\n",
       "                             data   zona  profissional        cep  \\\n",
       "0  <p class=\"text mb5px\">Hoje</p>  Norte         False  05172-090   \n",
       "1  <p class=\"text mb5px\">Hoje</p>  Norte         False  02844-090   \n",
       "2  <p class=\"text mb5px\">Hoje</p>  Norte          True  02311-010   \n",
       "3  <p class=\"text mb5px\">Hoje</p>  Norte         False  02248-030   \n",
       "4  <p class=\"text mb5px\">Hoje</p>  Norte         False  02329-060   \n",
       "\n",
       "           bairro  \n",
       "0   Vila Pirituba  \n",
       "1     Brasilândia  \n",
       "2     Vila Mazzei  \n",
       "3  Parada Inglesa  \n",
       "4   Jardim Hebrom  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_casa.reset_index(drop=True, inplace=True)\n",
    "df_casa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 704 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_casa.loc[:,df_casa.columns != 'cep'].to_excel('../1-OLX_WebScrap/1_OLX_CASA_SEM_CEP.xlsx')\n",
    "df_casa.to_excel('../1-OLX_WebScrap/1_OLX_CASA_COM_CEP.xlsx')\n",
    "df.to_excel('../1-OLX_WebScrap/1_OLX_TODOS_SEM_CEP.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

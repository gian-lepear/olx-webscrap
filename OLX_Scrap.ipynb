{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "import concurrent\n",
    "from time import sleep\n",
    "import folium\n",
    "from folium import plugins\n",
    "from IPython.display import display, Math, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que este notebook ira realizar:\n",
    "-------------------------------\n",
    "\n",
    "1. Acessar o site da olx utilizando a biblioteca **BeautifulSoup**, ecnontrar a lista de preços e salvar cada item em uma lista de \"Tags\"\n",
    "2. Encontrar os valores (municipio, estado , categoria, titulo, preco, link) de cada anuncio na lista\n",
    "3. Salvar em um DataFrame do Pandas\n",
    "4. Acessar cada um dos links de cada anuncio no DataFrame, no campo **href** e retira dele o CEP de cada anuncio criando um dicionario neste formato {\"href\":\"cep\"} **(Esta parte do codigo precisa ser aprimorada atualmente demora em torno de 5 à 7min para executar)**\n",
    "5. Adicionar o dicionario de CEP ao dataframe de anuncios utilizando a função _.map_ do Pandas \n",
    "6. Salvar o DataFrame resultante em uma planilha Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['municipio','estado', 'categoria', 'titulo', 'preco', 'href']\n",
    "valores = []\n",
    "li_list = []\n",
    "cep_dict = {}\n",
    "#soup_list = []\n",
    "url = \"http://sp.olx.com.br/sao-paulo-e-regiao/zona-leste/imoveis?o=\"\n",
    "regx = re.compile('\\d{5}-\\d{3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retornaSoupOLX(url, num):\n",
    "    for iter in range(num):\n",
    "        r = requests.get(str(url)+str(iter))\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        for ultag in soup.find_all('ul', {'class': 'list', 'id':'main-ad-list' }):\n",
    "            for litag in ultag.find_all(lambda tag: tag.name == 'li' and tag.get('class') == ['item']):\n",
    "                li_list.append(litag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiraEspecialString(string):\n",
    "    return string.text.replace('\\n','').replace('\\t','').replace('R$ ', '').replace('.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiraEspecialFloat(string):\n",
    "    return string.text.replace('\\n','').replace('\\t','').replace('R$ ', '').replace('.', '').replace(',', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def criaListaValores(li_list):\n",
    "    for elements in li_list:\n",
    "        x = BeautifulSoup(str(elements), 'html.parser')\n",
    "        #encontra a parte onde estão as informaçoes no html\n",
    "        info = x.find('div', {'class':'col-2'})\n",
    "        #encontra a string onde estão o municipio e estado separados por virgula\n",
    "        cidade_estado = tiraEspecialString(info.find('div', {'class':'OLXad-list-line-2'}).find('p', {'class':'text detail-region'}))\n",
    "        #encontra a categoria do anuncio\n",
    "        categoria = tiraEspecialString(info.find('div', {'class':'OLXad-list-line-2'}).find('p', {'class':'text detail-category'}))\n",
    "        #encontra o titulo do anuncio\n",
    "        titulo = tiraEspecialString(info.find('div', {'class':'OLXad-list-line-1 mb5px'}).find('h3', {'class':'OLXad-list-title mb5px'}))\n",
    "        #encontra o html do preço\n",
    "        preco = x.find('div', {'class':'col-3'})\n",
    "        \n",
    "        #trata o html do preço verificando se existe ou não\n",
    "        if preco.find('p', {'class':'OLXad-list-price'}):\n",
    "            preco = tiraEspecialFloat(x.find('div', {'class':'col-3'}).find('p', {'class':'OLXad-list-price'}))\n",
    "        else:\n",
    "            preco = 0.0\n",
    "        #retorna a tag href \"link do anuncio\"\n",
    "        href=x.find('a', {'class':'OLXad-list-link'})\n",
    "        \n",
    "        #retorna o conteudo do atributo href na tag href\n",
    "        href = href['href'].strip(' \\t\\n\\r')\n",
    "        #separa string  onde estão o municipio\n",
    "        municipio = cidade_estado.split(',',1)[1].strip(' \\t\\n\\r')\n",
    "        #separa o estado da string onde estão o municipio\n",
    "        estado = cidade_estado.split(',',1)[0].strip(' \\t\\n\\r')\n",
    "        categoria = categoria.strip(' \\t\\n\\r')\n",
    "        titulo = titulo.strip(' \\t\\n\\r')\n",
    "        valores.append([municipio, estado,categoria, titulo, preco, href])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCEP(url):\n",
    "    r = requests.get(url)\n",
    "    sleep(2)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    cep = soup.find(lambda tag: tag.name == 'strong' and tag.get('class') == ['description'] and regx.match(tag.text.strip(' \\t\\n\\r')) is not None)\n",
    "    if cep:\n",
    "        cep_dict.update({url:cep.text.strip(' \\t\\n\\r')})\n",
    "#         li_list2.append([url,cep.text.strip(' \\t\\n\\r')])\n",
    "    else:\n",
    "        cep_dict.update({url:''})\n",
    "#         li_list2.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "soup = retornaSoupOLX(url, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "criaListaValores(li_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.5 ms\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(valores, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 500 µs\n"
     ]
    }
   ],
   "source": [
    "list_href = list(df['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 55s\n"
     ]
    }
   ],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as e:\n",
    "     e.map(findCEP, list_href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3 ms\n"
     ]
    }
   ],
   "source": [
    "df['cep'] = df['href'].map(cep_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.87 s\n"
     ]
    }
   ],
   "source": [
    "df.to_excel('OLX_Scrap1.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
